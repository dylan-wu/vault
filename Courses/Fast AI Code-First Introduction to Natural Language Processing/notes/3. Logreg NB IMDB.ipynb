{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification the old-fashioned way:\n",
    "\n",
    "`Naive Bayes`, `Logistic Regression`, and `Ngrams`\n",
    "\n",
    "The purpose of this notebook is to show how sentiment classification is done via the classic techniques of `Naive Bayes`, `Logistic Regression`, and `Ngrams`. We will be using `sklearn` and the `fastai` library.\n",
    "\n",
    "In a future lesson, we will revisit sentiment classification using `deep learning`, so that you can compare the two approaches.\n",
    "\n",
    "The content here was extended from Lesson 10 of the fast.ai Machine Learning course. Linear model is pretty close to the state of the art here. Jeremy surpassed state of the art using RNN in fall 2017.\n",
    "\n",
    "## 0. The fastai library\n",
    "\n",
    "We will begin using the fastai library (version 1.0) in this notebook. We will use it more once we move on to neural networks.\n",
    "\n",
    "The fastai library is built on top of PyTorch and encodes many state-of-the-art best practices. It is used in production at a number of companies. You can read more about it here:\n",
    "- Fast.ai's software could radically democratize AI\n",
    "\n",
    "## 1. The IMDB dataset\n",
    "\n",
    "The large movie review dataset contains a collection of 50,000 reviews from IMDB, We will use the version hosted as part fast.ai datasets on AWS Open Datasets.\n",
    "\n",
    "The dataset contains an even number of positive and negative reviews. The authors considered only highly polarized reviews. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. Neutral reviews are not included in the dataset. The dataset is divided into training and test sets. The training set is the same 25,000 labeled reviews.\n",
    "\n",
    "The sentiment classification task consists of predicting the polarity (positive or negative) of a given text.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.utils.mem import GPUMemTrace #call with mtrace\n",
    "import sklearn.feature_extraction.text as sklearn_text\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the sample IMDb data set\n",
    "\n",
    "fast.ai has a number of datasets hosted via AWS Open Datasets for easy download. We can see them by checking the docs for URLs (remember ?? is a helpful command):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?? URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always good to start working on a sample of your data before you use the full dataset-- this allows for quicker computations as you debug and get your code working. For IMDB, there is a sample dataset already available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data set into a pandas dataframe, which we can inspect to get a sense of what our data looks like. We see that the three columns contain review label, review text, and the `is_valid` flag, respectively. `is_valid` is a boolean flag indicating whether the row is from the validation set or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'texts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the movie reviews from the sample IMDb data set.\n",
    "\n",
    "#### We will be using TextList from the fastai library:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "# throws `BrokenProcessPool' Error sometimes. Keep trying `till it works!\n",
    "\n",
    "count = 0\n",
    "error = True\n",
    "while error:\n",
    "    try: \n",
    "        # Preprocessing steps\n",
    "        movie_reviews = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
    "                         .split_from_df(col=2)\n",
    "                         .label_from_df(cols=0))\n",
    "        error = False\n",
    "        print(f'failure count is {count}\\n')    \n",
    "    except: # catch *all* exceptions\n",
    "        # accumulate failure count\n",
    "        count = count + 1\n",
    "        print(f'failure count is {count}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
